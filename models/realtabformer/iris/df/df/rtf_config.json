{"model_type": "tabular", "tabular_config": {"vocab_size": 89, "n_positions": 512, "n_embd": 864, "n_layer": 6, "n_head": 16, "n_inner": null, "activation_function": "tanh", "resid_pdrop": 0.07594191919929022, "embd_pdrop": 0.19380366539807364, "attn_pdrop": 0.16469325333835552, "layer_norm_epsilon": 7.183655237149971e-06, "initializer_range": 0.04773452438247231, "summary_type": "cls_index", "summary_use_proj": true, "summary_activation": null, "summary_first_dropout": 0.1, "summary_proj_to_labels": true, "scale_attn_weights": true, "use_cache": true, "scale_attn_by_inverse_layer_idx": true, "reorder_and_upcast_attn": false, "bos_token_id": 5, "eos_token_id": 6, "return_dict": true, "output_hidden_states": false, "output_attentions": false, "torchscript": false, "torch_dtype": "float32", "use_bfloat16": false, "tf_legacy_loss": false, "pruned_heads": {}, "tie_word_embeddings": true, "is_encoder_decoder": false, "is_decoder": false, "cross_attention_hidden_size": null, "add_cross_attention": false, "tie_encoder_decoder": false, "max_length": 20, "min_length": 0, "do_sample": false, "early_stopping": false, "num_beams": 1, "num_beam_groups": 1, "diversity_penalty": 0.0, "temperature": 1.0, "top_k": 50, "top_p": 1.0, "typical_p": 1.0, "repetition_penalty": 1.0, "length_penalty": 1.0, "no_repeat_ngram_size": 0, "encoder_no_repeat_ngram_size": 0, "bad_words_ids": null, "num_return_sequences": 1, "chunk_size_feed_forward": 0, "output_scores": false, "return_dict_in_generate": false, "forced_bos_token_id": null, "forced_eos_token_id": null, "remove_invalid_values": false, "exponential_decay_length_penalty": null, "suppress_tokens": null, "begin_suppress_tokens": null, "architectures": ["GPT2LMHeadModel"], "finetuning_task": null, "id2label": {"0": "LABEL_0", "1": "LABEL_1"}, "label2id": {"LABEL_0": 0, "LABEL_1": 1}, "tokenizer_class": null, "prefix": null, "pad_token_id": null, "sep_token_id": null, "decoder_start_token_id": null, "task_specific_params": null, "problem_type": null, "_name_or_path": "", "transformers_version": "4.28.0", "model_type": "gpt2"}, "checkpoints_dir": "rtf_checkpoints", "samples_save_dir": "rtf_samples", "epochs": 44, "batch_size": 8, "early_stopping_patience": 5, "early_stopping_threshold": 0, "training_args_kwargs": {"evaluation_strategy": "no", "output_dir": "rtf_checkpoints", "metric_for_best_model": "loss", "overwrite_output_dir": true, "num_train_epochs": 44, "per_device_train_batch_size": 8, "per_device_eval_batch_size": 8, "gradient_accumulation_steps": 2, "remove_unused_columns": true, "logging_steps": 100, "save_steps": 100, "eval_steps": 100, "load_best_model_at_end": false, "save_total_limit": 1, "optim": "adamw_hf", "report_to": "none"}, "train_size": 1, "mask_rate": 0.03635309194580345, "columns": ["sepal_length", "sepal_width", "petal_length", "petal_width", "species"], "column_dtypes": {"sepal_length": "float64", "sepal_width": "float64", "petal_length": "float64", "petal_width": "float64", "species": "object"}, "column_has_missing": {"sepal_length": false, "sepal_width": false, "petal_length": false, "petal_width": false, "species": false}, "drop_na_cols": ["sepal_length", "sepal_width", "petal_length", "petal_width", "species"], "processed_columns": ["0___NUMERIC___sepal_length_00", "0___NUMERIC___sepal_length_01", "0___NUMERIC___sepal_length_02", "0___NUMERIC___sepal_length_03", "0___NUMERIC___sepal_length_04", "0___NUMERIC___sepal_length_05", "0___NUMERIC___sepal_length_06", "1___NUMERIC___sepal_width_00", "1___NUMERIC___sepal_width_01", "1___NUMERIC___sepal_width_02", "1___NUMERIC___sepal_width_03", "1___NUMERIC___sepal_width_04", "1___NUMERIC___sepal_width_05", "1___NUMERIC___sepal_width_06", "2___NUMERIC___petal_length_00", "2___NUMERIC___petal_length_01", "2___NUMERIC___petal_length_02", "2___NUMERIC___petal_length_03", "2___NUMERIC___petal_length_04", "2___NUMERIC___petal_length_05", "2___NUMERIC___petal_length_06", "3___NUMERIC___petal_width_00", "3___NUMERIC___petal_width_01", "3___NUMERIC___petal_width_02", "3___NUMERIC___petal_width_03", "3___NUMERIC___petal_width_04", "3___NUMERIC___petal_width_05", "3___NUMERIC___petal_width_06", "4___CATEGORICAL___species"], "numeric_columns": ["sepal_length", "sepal_width", "petal_length", "petal_width"], "datetime_columns": [], "vocab": {"id2token": {"0": "[UNK]", "1": "[SEP]", "2": "[PAD]", "3": "[CLS]", "4": "[MASK]", "5": "[BOS]", "6": "[EOS]", "7": "[BMEM]", "8": "[EMEM]", "9": "[RMASK]", "10": "[SPTYPE]", "11": "0___NUMERIC___sepal_length_00___0", "12": "0___NUMERIC___sepal_length_01___4", "13": "0___NUMERIC___sepal_length_01___5", "14": "0___NUMERIC___sepal_length_01___6", "15": "0___NUMERIC___sepal_length_01___7", "16": "0___NUMERIC___sepal_length_02___.", "17": "0___NUMERIC___sepal_length_03___0", "18": "0___NUMERIC___sepal_length_03___1", "19": "0___NUMERIC___sepal_length_03___2", "20": "0___NUMERIC___sepal_length_03___3", "21": "0___NUMERIC___sepal_length_03___4", "22": "0___NUMERIC___sepal_length_03___5", "23": "0___NUMERIC___sepal_length_03___6", "24": "0___NUMERIC___sepal_length_03___7", "25": "0___NUMERIC___sepal_length_03___8", "26": "0___NUMERIC___sepal_length_03___9", "27": "0___NUMERIC___sepal_length_04___0", "28": "0___NUMERIC___sepal_length_05___0", "29": "0___NUMERIC___sepal_length_06___0", "30": "1___NUMERIC___sepal_width_00___0", "31": "1___NUMERIC___sepal_width_01___2", "32": "1___NUMERIC___sepal_width_01___3", "33": "1___NUMERIC___sepal_width_01___4", "34": "1___NUMERIC___sepal_width_02___.", "35": "1___NUMERIC___sepal_width_03___0", "36": "1___NUMERIC___sepal_width_03___1", "37": "1___NUMERIC___sepal_width_03___2", "38": "1___NUMERIC___sepal_width_03___3", "39": "1___NUMERIC___sepal_width_03___4", "40": "1___NUMERIC___sepal_width_03___5", "41": "1___NUMERIC___sepal_width_03___6", "42": "1___NUMERIC___sepal_width_03___7", "43": "1___NUMERIC___sepal_width_03___8", "44": "1___NUMERIC___sepal_width_03___9", "45": "1___NUMERIC___sepal_width_04___0", "46": "1___NUMERIC___sepal_width_05___0", "47": "1___NUMERIC___sepal_width_06___0", "48": "2___NUMERIC___petal_length_00___0", "49": "2___NUMERIC___petal_length_01___1", "50": "2___NUMERIC___petal_length_01___3", "51": "2___NUMERIC___petal_length_01___4", "52": "2___NUMERIC___petal_length_01___5", "53": "2___NUMERIC___petal_length_01___6", "54": "2___NUMERIC___petal_length_02___.", "55": "2___NUMERIC___petal_length_03___0", "56": "2___NUMERIC___petal_length_03___1", "57": "2___NUMERIC___petal_length_03___2", "58": "2___NUMERIC___petal_length_03___3", "59": "2___NUMERIC___petal_length_03___4", "60": "2___NUMERIC___petal_length_03___5", "61": "2___NUMERIC___petal_length_03___6", "62": "2___NUMERIC___petal_length_03___7", "63": "2___NUMERIC___petal_length_03___8", "64": "2___NUMERIC___petal_length_03___9", "65": "2___NUMERIC___petal_length_04___0", "66": "2___NUMERIC___petal_length_05___0", "67": "2___NUMERIC___petal_length_06___0", "68": "3___NUMERIC___petal_width_00___0", "69": "3___NUMERIC___petal_width_01___0", "70": "3___NUMERIC___petal_width_01___1", "71": "3___NUMERIC___petal_width_01___2", "72": "3___NUMERIC___petal_width_02___.", "73": "3___NUMERIC___petal_width_03___0", "74": "3___NUMERIC___petal_width_03___1", "75": "3___NUMERIC___petal_width_03___2", "76": "3___NUMERIC___petal_width_03___3", "77": "3___NUMERIC___petal_width_03___4", "78": "3___NUMERIC___petal_width_03___5", "79": "3___NUMERIC___petal_width_03___6", "80": "3___NUMERIC___petal_width_03___7", "81": "3___NUMERIC___petal_width_03___8", "82": "3___NUMERIC___petal_width_03___9", "83": "3___NUMERIC___petal_width_04___0", "84": "3___NUMERIC___petal_width_05___0", "85": "3___NUMERIC___petal_width_06___0", "86": "4___CATEGORICAL___species___Iris-setosa", "87": "4___CATEGORICAL___species___Iris-versicolor", "88": "4___CATEGORICAL___species___Iris-virginica"}, "token2id": {"[UNK]": 0, "[SEP]": 1, "[PAD]": 2, "[CLS]": 3, "[MASK]": 4, "[BOS]": 5, "[EOS]": 6, "[BMEM]": 7, "[EMEM]": 8, "[RMASK]": 9, "[SPTYPE]": 10, "0___NUMERIC___sepal_length_00___0": 11, "0___NUMERIC___sepal_length_01___4": 12, "0___NUMERIC___sepal_length_01___5": 13, "0___NUMERIC___sepal_length_01___6": 14, "0___NUMERIC___sepal_length_01___7": 15, "0___NUMERIC___sepal_length_02___.": 16, "0___NUMERIC___sepal_length_03___0": 17, "0___NUMERIC___sepal_length_03___1": 18, "0___NUMERIC___sepal_length_03___2": 19, "0___NUMERIC___sepal_length_03___3": 20, "0___NUMERIC___sepal_length_03___4": 21, "0___NUMERIC___sepal_length_03___5": 22, "0___NUMERIC___sepal_length_03___6": 23, "0___NUMERIC___sepal_length_03___7": 24, "0___NUMERIC___sepal_length_03___8": 25, "0___NUMERIC___sepal_length_03___9": 26, "0___NUMERIC___sepal_length_04___0": 27, "0___NUMERIC___sepal_length_05___0": 28, "0___NUMERIC___sepal_length_06___0": 29, "1___NUMERIC___sepal_width_00___0": 30, "1___NUMERIC___sepal_width_01___2": 31, "1___NUMERIC___sepal_width_01___3": 32, "1___NUMERIC___sepal_width_01___4": 33, "1___NUMERIC___sepal_width_02___.": 34, "1___NUMERIC___sepal_width_03___0": 35, "1___NUMERIC___sepal_width_03___1": 36, "1___NUMERIC___sepal_width_03___2": 37, "1___NUMERIC___sepal_width_03___3": 38, "1___NUMERIC___sepal_width_03___4": 39, "1___NUMERIC___sepal_width_03___5": 40, "1___NUMERIC___sepal_width_03___6": 41, "1___NUMERIC___sepal_width_03___7": 42, "1___NUMERIC___sepal_width_03___8": 43, "1___NUMERIC___sepal_width_03___9": 44, "1___NUMERIC___sepal_width_04___0": 45, "1___NUMERIC___sepal_width_05___0": 46, "1___NUMERIC___sepal_width_06___0": 47, "2___NUMERIC___petal_length_00___0": 48, "2___NUMERIC___petal_length_01___1": 49, "2___NUMERIC___petal_length_01___3": 50, "2___NUMERIC___petal_length_01___4": 51, "2___NUMERIC___petal_length_01___5": 52, "2___NUMERIC___petal_length_01___6": 53, "2___NUMERIC___petal_length_02___.": 54, "2___NUMERIC___petal_length_03___0": 55, "2___NUMERIC___petal_length_03___1": 56, "2___NUMERIC___petal_length_03___2": 57, "2___NUMERIC___petal_length_03___3": 58, "2___NUMERIC___petal_length_03___4": 59, "2___NUMERIC___petal_length_03___5": 60, "2___NUMERIC___petal_length_03___6": 61, "2___NUMERIC___petal_length_03___7": 62, "2___NUMERIC___petal_length_03___8": 63, "2___NUMERIC___petal_length_03___9": 64, "2___NUMERIC___petal_length_04___0": 65, "2___NUMERIC___petal_length_05___0": 66, "2___NUMERIC___petal_length_06___0": 67, "3___NUMERIC___petal_width_00___0": 68, "3___NUMERIC___petal_width_01___0": 69, "3___NUMERIC___petal_width_01___1": 70, "3___NUMERIC___petal_width_01___2": 71, "3___NUMERIC___petal_width_02___.": 72, "3___NUMERIC___petal_width_03___0": 73, "3___NUMERIC___petal_width_03___1": 74, "3___NUMERIC___petal_width_03___2": 75, "3___NUMERIC___petal_width_03___3": 76, "3___NUMERIC___petal_width_03___4": 77, "3___NUMERIC___petal_width_03___5": 78, "3___NUMERIC___petal_width_03___6": 79, "3___NUMERIC___petal_width_03___7": 80, "3___NUMERIC___petal_width_03___8": 81, "3___NUMERIC___petal_width_03___9": 82, "3___NUMERIC___petal_width_04___0": 83, "3___NUMERIC___petal_width_05___0": 84, "3___NUMERIC___petal_width_06___0": 85, "4___CATEGORICAL___species___Iris-setosa": 86, "4___CATEGORICAL___species___Iris-versicolor": 87, "4___CATEGORICAL___species___Iris-virginica": 88}, "column_token_ids": {"0___NUMERIC___sepal_length_00": [11], "0___NUMERIC___sepal_length_01": [12, 13, 14, 15], "0___NUMERIC___sepal_length_02": [16], "0___NUMERIC___sepal_length_03": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "0___NUMERIC___sepal_length_04": [27], "0___NUMERIC___sepal_length_05": [28], "0___NUMERIC___sepal_length_06": [29], "1___NUMERIC___sepal_width_00": [30], "1___NUMERIC___sepal_width_01": [31, 32, 33], "1___NUMERIC___sepal_width_02": [34], "1___NUMERIC___sepal_width_03": [35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "1___NUMERIC___sepal_width_04": [45], "1___NUMERIC___sepal_width_05": [46], "1___NUMERIC___sepal_width_06": [47], "2___NUMERIC___petal_length_00": [48], "2___NUMERIC___petal_length_01": [49, 50, 51, 52, 53], "2___NUMERIC___petal_length_02": [54], "2___NUMERIC___petal_length_03": [55, 56, 57, 58, 59, 60, 61, 62, 63, 64], "2___NUMERIC___petal_length_04": [65], "2___NUMERIC___petal_length_05": [66], "2___NUMERIC___petal_length_06": [67], "3___NUMERIC___petal_width_00": [68], "3___NUMERIC___petal_width_01": [69, 70, 71], "3___NUMERIC___petal_width_02": [72], "3___NUMERIC___petal_width_03": [73, 74, 75, 76, 77, 78, 79, 80, 81, 82], "3___NUMERIC___petal_width_04": [83], "3___NUMERIC___petal_width_05": [84], "3___NUMERIC___petal_width_06": [85], "4___CATEGORICAL___species": [86, 87, 88]}}, "tabular_max_length": 31, "tabular_col_size": 150, "col_transform_data": {"sepal_length": {"max_len": 10, "numeric_precision": 4, "mx_sig": 1, "has_negative": false, "ljust": 6, "zfill": 7}, "sepal_width": {"max_len": 10, "numeric_precision": 4, "mx_sig": 1, "has_negative": false, "ljust": 6, "zfill": 7}, "petal_length": {"max_len": 10, "numeric_precision": 4, "mx_sig": 1, "has_negative": false, "ljust": 6, "zfill": 7}, "petal_width": {"max_len": 10, "numeric_precision": 4, "mx_sig": 1, "has_negative": false, "ljust": 6, "zfill": 7}}, "in_col_transform_data": null, "col_idx_ids": {"0": [11], "1": [12, 13, 14, 15], "2": [16], "3": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "4": [27], "5": [28], "6": [29], "7": [30], "8": [31, 32, 33], "9": [34], "10": [35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "11": [45], "12": [46], "13": [47], "14": [48], "15": [49, 50, 51, 52, 53], "16": [54], "17": [55, 56, 57, 58, 59, 60, 61, 62, 63, 64], "18": [65], "19": [66], "20": [67], "21": [68], "22": [69, 70, 71], "23": [72], "24": [73, 74, 75, 76, 77, 78, 79, 80, 81, 82], "25": [83], "26": [84], "27": [85], "28": [86, 87, 88]}, "random_state": 1029, "numeric_nparts": 1, "numeric_precision": 4, "numeric_max_len": 10, "experiment_id": "df", "trainer_state": {"best_metric": null, "best_model_checkpoint": null, "epoch": 24.736842105263158, "global_step": 225, "is_hyper_param_search": false, "is_local_process_zero": true, "is_world_process_zero": true, "log_history": [{"epoch": 11.05, "learning_rate": 3.7373737373737376e-05, "loss": 0.556, "step": 100}, {"epoch": 22.11, "learning_rate": 2.474747474747475e-05, "loss": 0.4644, "step": 200}, {"epoch": 24.74, "step": 225, "total_flos": 35635353477120.0, "train_loss": 0.0910655763414171, "train_runtime": 8.3002, "train_samples_per_second": 451.795, "train_steps_per_second": 27.108}], "max_steps": 225, "num_train_epochs": 25, "total_flos": 35635353477120.0, "trial_name": null, "trial_params": null}, "target_col": null, "realtabformer_version": "0.1.3"}